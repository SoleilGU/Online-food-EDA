{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465615f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "RAW_DIR = Path(\"../data/raw\")\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CLEAN_DIR = Path(\"../data/clean\")\n",
    "CLEAN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOCAL_FALLBACK = RAW_DIR / \"onlinefoods.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d4dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = None\n",
    "try:\n",
    "  import kagglehub\n",
    "  dataset_dir = Path(kagglehub.dataset_download(\"sudarshan24byte/online-food-dataset\"))\n",
    "  print(\"KaggleHub ok:\", dataset_dir)\n",
    "except ImportError:\n",
    "  print(\"KaggleHub not available, using local fallback.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccb0c4e",
   "metadata": {},
   "source": [
    "# Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dd2f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_first_csv(folder: Path) -> pd.DataFrame:\n",
    "    files = sorted(folder.glob(\"*.csv\"))\n",
    "    \"\"\"Read the first CSV file in the given folder.\"\"\"\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No CSV files found in {folder}\")\n",
    "    print(\"Reading file:\", files[0])\n",
    "    try: return pd.read_csv(files[0])\n",
    "    except UnicodeDecodeError: return pd.read_csv(files[0], encoding=\"latin-1\")\n",
    "\n",
    "if dataset_dir:\n",
    "    df = read_first_csv(dataset_dir)\n",
    "elif LOCAL_FALLBACK.exists():\n",
    "    df = pd.read_csv(LOCAL_FALLBACK)\n",
    "else: raise FileNotFoundError(\"No dataset found. Please check the dataset directory or local fallback.\")\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c92df4",
   "metadata": {},
   "source": [
    "# Quick Health Check\n",
    "AIM: To gain an initial understanding of the structure and quality of the raw data and to locate \"obvious problems\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1777c91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa51f6ed",
   "metadata": {},
   "source": [
    "Change to binary type:\n",
    "- Gender: Male-0, Female-1\n",
    "- Output: No-0, Yes-1\n",
    "- Feedback: Negative-0, Positive-1\n",
    "Need to be dropped:\n",
    "- Unnamed 12\n",
    "To be transformed:\n",
    "- Marital Status\n",
    "- Occupation\n",
    "- Monthly Income\n",
    "- Educational Qualifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc559391",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84a382d",
   "metadata": {},
   "source": [
    "There is no NA data in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc8cd22",
   "metadata": {},
   "source": [
    "# Data Cleaning and Standardize\n",
    "Remove the Unnamed column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5d5280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "df = df.drop(columns=[\"Unnamed: 12\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e88c0e5",
   "metadata": {},
   "source": [
    " Change the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab51413",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = (df.columns.\n",
    "              str.strip()\n",
    "              .str.lower()\n",
    "              .str.replace(r'[^a-z0-9]+', '_', regex=True)\n",
    "              .str.strip('_'))\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c788ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"educational_qualifications\": \"education\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3150820",
   "metadata": {},
   "source": [
    "Change the type of pin_code into object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e32852",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pin_code\"] = df[\"pin_code\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb30376",
   "metadata": {},
   "source": [
    "# Choose the response variable\n",
    "Response variable: output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c8382e",
   "metadata": {},
   "source": [
    "The relationship between demographic/location factors and online food ordering behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9424b7a0",
   "metadata": {},
   "source": [
    "Select the first three digits of the pincode.\n",
    "AIM: to avoid noise affecting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969c1446",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"monthly_income\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b191602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_map = {\n",
    "  \"No Income\": 0.0,\n",
    "  \"Below Rs.10000\": 5000.0,\n",
    "  \"10001 to 25000\": 17500.0,\n",
    "  \"25001 to 50000\": 37500.0,\n",
    "  \"More than 50000\": 60000.0\n",
    "}\n",
    "\n",
    "df[\"income_mid\"] = df[\"monthly_income\"].map(income_map)\n",
    "print(\"Income midpoints:\", df[\"income_mid\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000c274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"y_ordered\"] = df[\"output\"].map({\"No\": 0, \"Yes\": 1})\n",
    "df_model = df[df[\"y_ordered\"].isin([0, 1])].copy()\n",
    "print(\"counts:\", df_model[\"y_ordered\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72be68c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_model\n",
    "print(\"shape:\", data.shape)\n",
    "print(\"\\nhead():\")\n",
    "print(data.head(3))\n",
    "print(\"\\ndtypes:\")\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2fee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.isna().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e695eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [ c for c in [\"age\", \"family_size\", \"income_mid\", \"pin_code\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b549c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, roc_auc_score, f1_score\n",
    "\n",
    "props = df_model[\"y_ordered\"].value_counts(normalize=True)\n",
    "y_true = df_model[\"y_ordered\"]\n",
    "p_pos = props.get(1, 0.0)\n",
    "maj = 1 if p_pos > 0.5 else 0\n",
    "pred_majority = np.full_like(y_true, maj)\n",
    "\n",
    "null_acc = (pred_majority == y_true).mean()\n",
    "null_f1 = f1_score(y_true, pred_majority)\n",
    "\n",
    "print(f\"\\nNull accuracy (always predict {maj}): {null_acc:.3f}\")\n",
    "print(f\"Null F1 (positive class): {null_f1:.3f}\")\n",
    "\n",
    "proba_null = np.full(y_true.shape[0], float(p_pos))\n",
    "print(\"Null LogLoss:\", round(log_loss(y_true, proba_null), 3))\n",
    "print(\"Null AUC    :\", roc_auc_score(y_true, proba_null))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceb54b4",
   "metadata": {},
   "source": [
    "The accuracy of null model is 0.776, which means the dataset is unbalance.\n",
    "For the future model, the LogLoss should be lower than Null LogLoss - 0.532, and the AUC should be higher than 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456a7c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [ c for c in [\"age\", \"family_size\", \"income_mid\"]]\n",
    "cat_cols = [ c for c in [\"gender\", \"marital_status\", \"occupation\", \"education\", \"pin3\"]]\n",
    "\n",
    "x = df_model[num_cols + cat_cols].copy()\n",
    "y = df_model[\"y_ordered\"].copy()\n",
    "\n",
    "print(\"numerical features:\", num_cols)\n",
    "print(\"categorical features:\", cat_cols)\n",
    "print(\"x shape:\", x.shape, \"| y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703c1eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "features = num_cols + cat_cols\n",
    "rows = []\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for f in features:\n",
    "    xf = x[[f]].copy()\n",
    "    if f in num_cols:\n",
    "        prep = ColumnTransformer([(\"num\", Pipeline([\n",
    "            (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"sc\", StandardScaler())\n",
    "        ]), [f])])\n",
    "    else:\n",
    "        prep = ColumnTransformer([(\"cat\", Pipeline([\n",
    "            (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        ]), [f])])\n",
    "\n",
    "    clf = Pipeline([(\"prep\", prep),\n",
    "                    (\"lr\", LogisticRegression(max_iter=300, class_weight=\"balanced\"))])\n",
    "\n",
    "    scores = []\n",
    "    for tr, va in skf.split(xf, y):\n",
    "        clf.fit(xf.iloc[tr], y.iloc[tr])\n",
    "        proba = clf.predict_proba(xf.iloc[va])[:, 1]\n",
    "        scores.append(roc_auc_score(y.iloc[va], proba))\n",
    "\n",
    "    rows.append({\"feature\": f,\n",
    "                 \"cv_auc_mean\": float(np.mean(scores)),\n",
    "                 \"cv_auc_std\":  float(np.std(scores))})\n",
    "\n",
    "uni_auc = pd.DataFrame(rows).sort_values(\"cv_auc_mean\", ascending=False)\n",
    "print(uni_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
